* conceptos
** tdbc para un desarrollo conjunto a partir de ahora
ir programando sqlite3 con tbdc cosa que sirva el mismo proc y el
mismo metodo para ambos mundos como ya lo tengo con llenax resulset.
** uso abreviado del resulset
#+BEGIN_SRC 
set recordset [[db prepare "select * from clientes"] execute ]
#+END_SRC
** nuevo look
el look basico sin el optiondatabase. Que para la notebook es tiny,
para mi compu es un poco mas grande y para la del fede sera mas grande
pq se arregla agrandando el tipo de letra.
Es un look claro y limpio como el theme que tengo en emacs ahora
(leuven), fondo blanco, azul, bisque, amarillo, lightyellow,
celeste. En los tbls uso el pink/lightblue/lightgreen. Y de ultima
jugaria con un optiondatabse diferencial para el Fede luego.
No deja de ser extenuante de todos modos el tema color y diseño. Por
ahi el diseño y color estilo F13 es agradable luego de años del tosco
fondo #333333 y el alto contraste que presenta el tablelist con
colores chocantes a la vista. Lo que no hay que hacer es que el
colorinche penalice el tiempo de apertura como en stock, eso es
inaceptable.
** funcionamiento del prepare/stmt/resultset
se puede hacer el prepare con =: o sea no molesta el {} ya que no es
lo mismo hacer zona=:zona que zona=$zona, incluso funciona en los
casos de calle=:calle cuando calle es {Obispo Castellano} o sea nos
olvidamos de entrecomillar nosotros. 
Luego que el prepare esta listo cuando se dispara el execute, se busca
el valor que tiene la variable en el ambito que llamo el execute y si
no existe la variable se pone null, salvo que luego del execute
agreguemos un dict {calle Solares} O sea de una inteligencia total.
** clipboard
aparte de la sencillez de clipboard clear, clipboard append, ahora
tengo clipboard get facil para bindear a <3>
bind .dni <3> {set dni [clipboard get]}
y nada mas no hace falta limpiar ni nada, 
** $resultset nextdict vardict
directamente te tira un row como diccionario en forma muy directa
luego para sacar la variable chequeamos con dict exists y luego dict
get pq sino da error.

#+BEGIN_SRC
foreach w {nombre calle num barrio wapp tel} {
    if {[dict exists $cliente $w]} {
    set $w [dict get $cliente $w]
}}
#+END_SRC

tener en cuenta tambien que se puede transformar ese dict en un array
muy facilmente 
p.e.
$resulset nextdict dictcliente
array set cliente $dictcliente ;# donde se paso el dict al array
luego $cliente(nombre) $cliente(calle) etc seran operativos por lo
cual estariamos en la misma operatividad que teniamos con el viejo
sqlite solo con una linea de codigo. o sea array set.
Esto es repractico pq no tenemos que andar con un monton de variables
y solo globalizamos el nombre del array, y el manejo automatico de los
nombres de las columnas de la tabla lo hace el dict/array.
** el resaltado en proc aparte
como ya lo vengo haciendo es mas claro de mantener y de ubicar, muchas
veces tienen el mismo patron, y practicamente se agrupan los proc con
el mismo prefijo o sea empiezan con res y ya sabemos que es un resaltado.
** cambios en llenarx / recalcx
para evitar problemas e integrar recalcx hice los siguientes cambios:
1. el metodo recalc le puse un if inicial que se fija si la variable
   _tdbc es 1 y pasa por alto todo y directamente llama a
   recalcx. recalcx lo que hace es llenarx $_stmt $_res siendo estas
   ambas variables guardadas oportunamente
2. lamentablemente no puedo trabajar con resulset sino un paso mas
   atras con stmt y hacer que el resultset lo calcule el llenarx. O
   sea hago el prepare directo
   set stmt [db prepare sql]  y eso envio al llenarx.
3. La unica desventaja (y lo que me hizo perder mucho tiempo) es que
   pierdo el :var y la lectura local del ambito llamante, lo cual es
   obvio usandose asi como metodo y menos guardandose en la clase para
   un recalculo. Asi que el stmt se debe hacer entrecomillado y
   calculado con las variables del momento con $, cuidando los ''
   respectivos y enviar el stmt que responda a lo local, sino ese
   prepare no obtendra ningun resultado en la clase.
   PRESTAR ATENCION QUE ESTE ES EL MAYOR PROBLEMA CUANDO UN LLENARX NO
   FUNCIONA Y ES QUE EL ENVIADO DE VARIABLES CON =: NO FUNCIONA Y HAY
   QUE HACERLO CON $.

** tema current_timestamp/datetime
en sqlite el current_timestam se guarda en en UTC o sea en GMT lo cual
difiere 3 hs lo nuestro. Lo cual es considerado una buena practica a
nivel base de datos.
Para expresarlo en los formularios hay que hacer la transcripcion a
localtime, mediante la funcion datetime(campofecha,'localtime'), con
el modificador 'localtime' se logra que se muestre la hora correcta.
** operador ternario x?y:z
ES X V O F?? --> si es verdad y si es falso z 
PREGUNTA ? VERDAD : FALSO

If-then-else, as in C. If x evaluates to non-zero, then the result is
the value of y. Otherwise the result is the value of z. The x operand
must have a boolean or numeric value.

#+BEGIN_SRC
    foreach row [range 0 [expr [$tbl size]>200?200:[$tbl size]]] {
#+END_SRC
Aca se pudo usar el operador ternario para con compacidad y elegancia
prever dos opciones:
si el tamaño de la tabla era mayor de 200 se usaba el maximo de 200 y
si el tamaño era menor se usaba el size de la tabla. 
En este caso x es [tbl size]>200 cuando esa expresion da 1 o sea
cuando es verdadera se gatilla el y o sea se obtiene 200, y cuando esa
expresion es falsa o sea 0, se obtiene z que seria el size.
El error que cometia yo era no poner el comando expr y encerrarlo como
comando, y alli me recorde el aforismo que habia leido por ahi:
EN TCL NO PIENSE EN STATEMENTS SINO EN COMANDOS.
el comando es expr y al ser un comando a evaluar hay que encerrarlo en
[], y los elementos del comando son en este caso x?y:z, x lo que puede
dar verdad o falso, y si es verdad y z si es falso.
* proyectos
** DONE catalogo/catalogopg
- State "DONE"       from "TODO"       [2019-04-04 jue 20:16]
este lo tuve que dividir porque hay una situacion de datos que hace
imposible mantenerlos juntos. Pero los voy llevando unidos desde ahora
o no los hare mas.
Tiene un tbls de tablas, (en caso de sqlite filtra las views
indeseables), y luego automaticamente muestra las columnas y el
contenido de las ultimas 100 filas, y con doble click en el bodytag
del tablelist obtengo la totalidad de los registros.
** DONE autorizador
- State "DONE"       from "TODO"       [2019-04-15 lun 14:05]
seria un megaform que tome el DNI que pueda pegarse con boton derecho
y/o un boton, que busque en romitex y entregue toda la info en forma
clara y concisa en formatos de colores y tablas bien visibles.

Como segunda parte que tenga un registro de las autorizaciones pedidas
con fecha y hora y su resultado, pq abajo se pondria si fue autorizado
o rechazado. 


Por el momento estoy en la simpleza de mostrar una tabla con los datos
en un tbls y ver la direccion.
Me movere ahora en la de autorizar/rechazar y ver las "direcciones" en
las cuales van vendiendo para ver que no haya problema ahi lo cual
puede ser dificultoso cuando vayan avanzando.

Pero queda el problema de las direcciones de los que no sean clientes
para ver si hay ventas en la direccion. alli habra otro cuadrito de
entrada con calle y numero.

Tendriamos que ir un paso mas alla ahora y buscar que la direccion no
aparezca ni en la aclaracion ni en ningun otro campo, para evitar el
efecto usuahia 1872.

Agregue link a comentarios viejos y nuevos.
Por el momento no veo nada para agregar.
*** agregar los autorizados que no son de romitex aunque sea solo dni
*** agregar promotor
*** agregar/cargar datos de los rechazados no romitex
*** emitir diariamente un archivo enviable de resumen de autorizados/rechaz.
*** DONE URG: ESTIMADOR DE FORMA DE PAGO
- State "DONE"       from "TODO"       [2019-04-11 jue 19:03]
propongo un analisis de los pagos anteriores mediante una exposicion
clara por medio de una coloracion entre roja y blanca, o sea termica
que indique si pago atrasada o pago al dia, con ciertos parametros que
indique a simple vista si alguien sirve o no sirve.
Para lo cual necesitaria tener un campo en la tabla pagos de cantidad
de dias de atraso, para lo cual necesitaria un vencimiento.
Pienso que podria "armar" un vencimiento mediante ir poniendo o
sumando a los importes pagados la fecha.
O sea puedo poner una columna cuota efectiva haciendo una sumatoria
del pago, o sea si tengo una cuota de 300 y pago 100 es cuota 1, luego
pago 200 sigue siendo cuota 1, pago 300 es cuota 2, etc. O sea tiene
que hacerse un algorritmo para que cargue en los pagos el numero de
cuota que corresponde. Una vez con numero de cuota, facilmente se le
calcula cuando vencio esa cuota, y que atraso tuvo al pagar, y que
color le corresponde.
Todo es un algorritmo.
Si a ese algorritmo le sumamos una actualizacion de las cuotas, o sea
ver el importe actualizado, lo cual obtenemos por una funcion logramos
que el operador este en mejores condiciones para decidir el credito. 
hecho en forma genial pienso, una vez puesto en la forma de hacer los
ciclos con db eval salio todo tal cual lo pensaba, es mas facil
hacerlo que plantearlo.
Ahora pienso que hacerlo mientras se pasan los pagos va a ser mas
facil aun.
El actualizador de cuotas funciona pero le faltan datos monetarios al
array, para que sea mas relevante, podria hacerlo morder year-month y
en todos los year hacerlos igual a los datos y en el 18 poner todos
los datos cosa de que no distorsione tanto.
Creo que el adecuar los datos es algo semitedioso que se puede hacer
cada seis meses o un año, se deberia poder tener otra solucion que
solo agregue los ultimos guarismos y no tenga que cambiar todo.
*** DONE agregar busqueda por nombre
- State "DONE"       from "TODO"       [2019-04-15 lun 13:59]
*** TODO adecuar pasar pagos para que anote que cuota corresponde el pago
*** CAMBIOS EN EL CONCEPTO:
elimino el concepto de anotar y registrar los aprobados y rechazados,
por el hecho que es una idea fallada pq es parcial, ya que el universo
de romitex es una parte de los rechazos totales, la mayoria de los
cuales son por seven. 
En la idea nueva en la cual no filtrariamos por seven mucho sentido no
tiene anotar los aceptados y los rechazados dentro de la base de
datos.
Si en cambio tendria sentido agregar a la base de datos los morosos
que descubrieramos del seven que rechazaramos por ese motivo y los
cargaramos para ponerlos en lista negra, pero en realidad es tedioso
hacerlo, y si no se hace con todos los datos tampoco sirve mucho luego
como base segura para la reprobacion de un credito. Y de nuevo con el
sistema nuevo no va a existir mucho de este sistema.
** ventas
por el momento estoy ordenando basado en los siguientes puntos
1. saco el colorscheme dejando el nuevo natural colorscheme
2. saco los larguisimos procesos de los binds y los buttons a proc y
   los voy ordenando
3. saco el buscar padron por nombre pq resulto en la practica no usado
4. cambio los colores rosa por dodgeblue2
5. MUYIMPORTANTE: cambio el sqlite db eval por tdbc::sqlite por mas
   que es mas verbose que el otro crea la base para la transformacion
   para postgres
6. voy solucionando los problemas ergonomicos esa es la idea tambien,
   p.e. el tema sexo que lo pase a botones.
7. correccion de pequeños bugs anteriores como la falta de limpiado
   del wassap.
8. tambien va una correccion a nivel codigo que estaba improlijo los
   margenes.
visualmente va quedando muy bien y conceptualmente va quedando pulido
con la experiencia acumulada en estos meses.
Hoy di un paso gigante en la ergonomia creo con la solucion del paso
de los combos con el KP_Enter, veremos como funciona en el teclado de pc.
*** Falta
1- edicion poder borrar registros:
se agrego poder borrar registros y agregar registros y editar
continuamente cualquier registro menos el id. 
2. visualizar ficha bien desde listado no adhoc
3. ver el tab denso
** DONE test gui
- State "DONE"       from "TODO"       [2019-04-15 lun 20:01]
traer los elementos de mantenimiento de la base de datos pero en una
gui de vision continua pq el otro demostro ser inusable.
Doy prioridad a esto por lo necesario.
No estan pasados todos los tests sino los que dan positivos, la idea
es que luego de corregir se corra el test de consola tambien y no de
ninguna salida, y que si alguna vez da salida ir agregando lo que de
salida.


* Ideas en general
** ir depurando comentarios a mano
va a ser la unica manera de salir de eso
** agregar campos de info no visible en ficha pero util para informacion
como un campo direccion relacionada, un campo persona relacionada, o
acaso ese concepto se une al anterior, un campo que se pueda anotar en
el momento de la venta pq sigo anotando o bien en infoseven o en
comentarios viejos, un campo para que quede la info en primera plana
para la aprobacion o denegacion de creditos futuros que tenga
prioridad sobre todos los otros items o sea que sea como el campo
nuevo. y lo que diga ese campo nuevo no se discute.
** tener en cuenta que tdbc::sqlite no tienen manejo de funciones
* Postgres
creo que hay que escribir todo de nuevo y comenzar un nuevo mundo
totalmente simplificado y nuevo teniendo en cuenta unicamente lo que
se hace ahora, solo tomando los datos que necesitamos. 
O sino olvidarnos del tema para siempre.
La idea que programando en tdbc iba a poder acercar los mundos no
anduvo, hay muchas incompatibilidades. Y las programaciones son muy
complejas tienen distintos vicios que no queremos dejar de lado por no
querer empezar de cero todo. 
Creo que tendria que trabajar unos dos meses sobre la creacion de un
sistema desde cero en postgres y olvidarme del sistema de sqlite. 
Hacer lo que tenemos ahora:
1. buscador
2. pasador de ventas
3. pasador de recibos
4. fichas
5. stock y caja
A un promedio de quince dias cada uno tenemos dos meses y medio.
Y basarnos en las tablas simplificadas que vamos pasando desde
postgres como venimos haciendo.
DECLARO SOLEMNEMENTE QUE EN MENOS DE CUATRO MESES TENGO ROMITEX CON
POSTGRES

en solo dos minutos con postgres3 cargo
zonas,barrios,calles,clientes,ventas y pagos, y de paso corrijo
errores.
postgres 3.1 corrio rapido pero tuve problemas con tabla visitas, que
debo ver pq no la quiso cargar.
y descubri un bug que se esta generando en tabla recorridos.
(notar que ambas son tablas de servicio y no son esenciales a los
datos de romitex core.)
postgres5 que produce la tabla cuotas demora 20 minutos pero corre sin
errores por lo menos.
* tcl-postgres
** diario programacion
*** [2019-04-25 jue] creacion directorio git postcl
alli concentraremos todo el proyecto
*** [2019-04-25 jue] padron 
creacion del padron en postgres, falta solo dump
*** [2019-04-25 jue] busqueda automatica de dni para pasado de ventas
inteligencia para no confundir cuando hay dos dni iguales, para no
tener que estar trabado con romitex/padron/femenino y masculino
*** [2019-04-25 jue] trabado por el bug de tdbc de no guardado con array
o sea cuando un un insert o update detecta un () da error, y eso nos
complica enormemente las cosas a nivel de formularios.
*** [2019-04-25 jue] total definicion para Ptcl 
gracias al bug de tdbc me fui para ptcl recupere lo ya conocido y veo
que es un desarrollo muchisimo mas acabado, y en realidad no debo
temer qeu no siga en desarrollo pq lo mismo tdbc no lo tocan hace diez
años. O sea que no creo que haya problema.
Ahi tengo total integracion de array en varios formatos o sea que no
creo tener problemas y aparte es mas tipo tcl o sea que p.e. los
comando permiten el loop dentro de la consulta tipo el eval, cosa que
este otro no lo hacia o sea no se como iba a resolverlo llegado el
caso. Pero ahora lo tengo. O sea tengo array y tengo proc de loop. Y
tengo llist, y tengo procedimientos en postgres que se pueden
programar con tcl.
*** [2019-04-26 vie] solucion del problema de las ids
un problema que me llevo casi dos horas: o sea cuando iba a insertar
un registro me lo ingresaba con un id=1 y por supuesto me lo
rechazaba.
O sea que la sequencia generaba valores pero start a partir de 1.
Y se puede programar en forma muy flexible como queremos los valores,
a partir de cual, de dos en dos, etc.
Lo que debo hacer es programar las sequencias con el valor minimo de
las filas que hay en el minuto cero y desde alli empiezan a andar.
Se trato de un problema angustioso pq hasta ahora en postgres solo
habia hecho consultas y practicamente no habia hecho insersiones, y
tener este problema con los id causaba sosobra de entrada.
*** [2019-04-26 vie] problema aprendizaje sequences/serial/
vi que solucionamos el problema de los id con poner la columna id como
serial, en el modelo directamente, y como primary key, luego poner en
el script de entrada de datos el setval calculado en funcion del
ultimo id asignado en la tabla para tener una continuidad
automatizada. Con eso solucione el problema y lo hice en una forma
automatizada, pq sino no se podria trabajar.
Tambien solucione el tema de los id pasando todas las tablas a id
serial, siendo el seudotipo serial el mas conveniente pq te ahora el
tener que crear una sequencia a mano, haciendo toda la tarea por
vos. Deje las nueve secuencias ya creadas para no enquilombar por hoy
pero al lo mejor algun dia las saco y dejo todo serial., Lo bueno que
funciona el automatismo.
*** [2019-04-26 vie] recreacion de los padrones sin id para ahorrar espacio
cree las tablas en pgmodeler y el proceso se hizo muy rapido, fue cosa
de unos segundos emitir los csv y la lectura del copy que ya estaba
guardado fue rapidisima. igual el indexado.
*** [2019-04-26 vie] primera parte del pasado de venta
automatizado el tema cliente/padron/doblepadron/noestaenpadron- con
una señalizacion clara y permanente solo una minima e imperceptible
linea de detalle en el diseño que afea pero por lo demas es todo
excelente.
Ahora tendria que ir a los dos procesos de update/creacion de cliente
y al logde cambio, pero como pg maneja array sera claro y facil. Capaz
en este finde transite esa parte para quedar el paso de los articulos
para la semana que viene.


** DONE padron
- State "DONE"       from "TODO"       [2019-04-25 jue 15:16]
:LOGBOOK:
CLOCK: [2019-04-25 jue 14:01]--[2019-04-25 jue 15:16] =>  1:15
:END:
habilitar padron para uso en postgres y uso en busqueda en ventas.
primero emito desde sqlite sendos archivos csv para copiar desde
posgres.
creo las tablas desde posgres y luego con el comando copy levanto el
csv en las tablas.
.1 en sqlite: .output fem.csv .mode csv
.2 en sqlite: select * from fem order by dni; asi emito el csv
.3 inspecciono con emacs y corrijo una linea del fem
.4 obtengo el ancho de los campos nombre y dni para no hacer anchos al
vicio los campos de la tabla
.5 select max(length(nombre)) from fem;
.6 en postgres como usuario hero: creo la tabla
CREATE TABLE femenino (
id serial NOT NULL,
DNI character varying(8),
NOMBRE character varying(54),
CONSTRAINT femenino_pkey PRIMARY KEY (id))
.7 en postgres como usuario postgres: 
COPY masculino(dni,nombre)
FROM '/home/hero/mas.csv' DELIMETER ',' CSV HEADER;
** TODO padron dump y restore

